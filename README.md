# CLI-Agent-Templates
guardrail and prompt format docs


The only way to get reliable, production-grade results from LLM coding agents (especially in complex/brownfield repos) is through spec-first development, frequent intentional compaction, and strict control over the context window.

You must stop shouting at the agent and start managing its information diet with surgical precision.

â¸»

ğŸ”‘ High-Value Takeaways (Organized by Concept)

1. Spec-First Development Is Mandatory
	â€¢	Dexâ€™s team at HumanLayer moved from line-by-line code reviews to trusting well-written specs.
	â€¢	Now, they only review:
	â€¢	Research docs (how the system works)
	â€¢	Planning docs (what will change, how it will be tested)
	â€¢	They donâ€™t read the actual code anymore unless necessary.
	â€¢	â€œA bad line of code is bad. A bad spec leads to 100s of bad lines. A bad line of research leads to 1000s.â€

â¸»

2. Context Management Is Everything

â€œEverything that makes coding agents good is context engineering.â€

	â€¢	LLMs are pure functions. Their only input is the context window.
	â€¢	Garbage in â†’ garbage out.
	â€¢	Goals:
	â€¢	ğŸŸ© Correctness
	â€¢	ğŸŸ© Completeness
	â€¢	ğŸŸ© Compactness
	â€¢	ğŸŸ¨ Trajectory (vibes-based for now)

â¸»

3. Frequent Intentional Compaction
	â€¢	Donâ€™t just â€œrestartâ€ when things go bad. Thatâ€™s naive.
	â€¢	Instead, do intentional compaction:
	â€¢	Log whatâ€™s done.
	â€¢	Clear agent memory.
	â€¢	Start next step with a focused context window.

Tools:
	â€¢	Write structured progress.md files after each stage.
	â€¢	Keep context utilization below 40%.
	â€¢	Use files like:
	â€¢	research.md: what the system is doing (with file names + line numbers)
	â€¢	plan.md: what changes will be made
	â€¢	implement.md: code writing, step by step

â¸»

4. Three Phases of Context-Aware AI Dev
	1.	Research â€“ understand system flow, file interdependence, where things live.
	2.	Plan â€“ write detailed high-level plans of what to change, where, and how to test it.
	3.	Implement â€“ short sessions of actual code generation, informed by above.

	â€¢	If implementation fails, the problem was in the plan â€” not the model.
	â€¢	If the plan was bad, the research was flawed.

â¸»

5. Sub-Agents for Inline Compaction
	â€¢	Use sub-agents (e.g., Claude tools or OpenAI function calling) for reading/searching tasks.
	â€¢	Parent agent offloads reading 50+ files to a sub-agent â†’ keeps main context clean.
	â€¢	Main agent receives distilled results, gets back to work.

â€œSub-agents arenâ€™t about being a frontend or PM â€” theyâ€™re about memory offloading.â€

â¸»

6. Code Review is Mental Alignment
	â€¢	Purpose of code review = maintain shared understanding.
	â€¢	Canâ€™t review 2000 lines of Go every day, but can review 200 lines of plan.md.
	â€¢	Teams should prioritize mental alignment over nitpicking code.

â¸»

7. Real World Proof
	â€¢	Dex helped:
	â€¢	Ship a PR into a 300K-line Rust codebase without prior context â†’ got merged
	â€¢	Pair-program with a CEO to ship 35K lines of code in one day (adding WASM support to a language)
	â€¢	Intern on Dexâ€™s team shipped 10 PRs in 1 day after onboarding into this system.

â¸»

ğŸ§ª Sample Workflow (Inferred from Talk)

1. Run research agent
   â†’ Generates research.md (file paths, line numbers, flow)

2. Human reviews research â†’ tweaks if needed

3. Run planning agent
   â†’ Generates plan.md (exact changes, rationale, test plan)

4. Human approves plan

5. Run implementation agent in small steps
   â†’ Constantly compact context

6. Log completed tasks into progress.md
   â†’ Prepare next round of implementation


â¸»

âš ï¸ Warnings and Anti-Patterns
	â€¢	Donâ€™t:
	â€¢	Shout at agents in an endless loop (/compact is trash)
	â€¢	Let them â€œvibeâ€ in massive repos without constraints
	â€¢	Start implementing before research + planning are solid
	â€¢	Do:
	â€¢	Treat context like sacred real estate
	â€¢	Use markdown files for logging progress between sessions
	â€¢	Build your entire workflow around context preservation

â¸»

ğŸ§  Best Quotes

â€œI havenâ€™t opened a non-markdown file in 2 months.â€

â€œI donâ€™t read code anymore. I read specs.â€

â€œA bad part of a plan can be 100s of bad lines. A bad research line = 1000s.â€

â€œThe only thing that matters in code agents is the context window.â€

â¸»

ğŸ“¦ Resources Mentioned
	â€¢	Dexâ€™s podcast episode on coding agents fixing a large Rust repo (w/ BAML)
	â€¢	SourceAmp + â€œRalph Wiggum as a software engineerâ€ (on smart prompting)
	â€¢	All prompts and files are open source (linked via QR code in talk)

â¸»

âœ… What to Apply Right Now
	â€¢	Switch from code-first to spec-first dev.
	â€¢	Add a progress.md and update it after every PR/step.
	â€¢	Implement a 3-step loop: Research â†’ Plan â†’ Implement.
	â€¢	Set hard rules on max context usage (<40%) per agent loop.
	â€¢	Use intentional compaction instead of /clear or /reset.



AI is not good software but itâ€™s good peopleâ€”itâ€™s a super eager intern that needs guidance, structure, and coaching to produce great results. Most users fail not because the AI is weak, but because they donâ€™t provide the right context. This talk introduces Context Engineering as the evolved version of prompt engineering.

â¸»

ğŸ”‘ High-Value Tactics and Concepts

1. AI is Like a Tireless Intern, Not a Senior Engineer
	â€¢	Itâ€™s always eager to say yes, even when it shouldnâ€™t.
	â€¢	If it says, â€œCheck back in 15 minutes,â€ itâ€™s dodging because it doesnâ€™t want to say â€œI donâ€™t know.â€
	â€¢	You must coach it like a junior employee: Give clear instructions, allow it to ask questions, and demand honest feedback.

â¸»

2. Context Engineering â‰  Prompt Engineering

Context engineering = â€œPrompt engineering on steroids.â€
Itâ€™s about giving the AI all the background, expectations, and examples it needs.

Example:
	â€¢	âŒ â€œWrite me a sales email.â€ â†’ generic result.
	â€¢	âœ… â€œWrite a sales email using my brand tone, based on this customer transcript, referencing these product specs.â€

ğŸ“Œ Rule of thumb: If a human couldnâ€™t complete the task with your prompt alone, the AI probably canâ€™t either.

â¸»

3. Chain of Thought Reasoning

Add to your prompt:
ğŸ‘‰ â€œBefore you respond to my query, walk me through your thought process step-by-step.â€

Why it works:
	â€¢	LLMs donâ€™t generate answers holistically. They generate one word at a time.
	â€¢	Asking for reasoning encourages it to plan before writing.
	â€¢	You get transparency: both output and its assumptions.

â¸»

4. Few-Shot Prompting (Examples)

Show AI what you want by including:
	â€¢	âœ… Good examples (â€œHereâ€™s an email I likeâ€)
	â€¢	âŒ Bad examples (â€œHereâ€™s one I donâ€™t wantâ€)

You can even ask the AI:

â€œCreate the opposite of this good example, and explain why itâ€™s bad.â€

Examples are far more effective than adjectives like â€œmake it sound professional.â€

â¸»

5. Reverse Prompting

Ask the model to ask you questions before it starts.

Prompt template:

â€œHelp me write a sales email.
Walk me through your thought process.
Reference this good example.
Before you start, ask me anything you need to do a good job.â€

This prevents hallucination by forcing it to gather missing info instead of guessing.

â¸»

6. Assigning Roles (Persona Prompting)

Tell the AI who it is. This steers it toward the right knowledge and tone.

Example:
	â€¢	â€œYouâ€™re Dale Carnegie. Give me feedback on this email using your principles.â€

Roles create a knowledge domain filter and shape tone, context, and depth.

â¸»

7. Constraint Collisions

Push creativity by assigning random constraints or personas:
	â€¢	How would Elon Musk solve this?
	â€¢	How would Jerry Seinfeld?
	â€¢	How would Amazon?

Useful both for human ideation and for breaking LLMs out of ruts.

â¸»

8. Tough Conversation Flight Simulators

Use GPT to rehearse difficult real-life conversations by:
	1.	Creating a personality profiler for your conversation partner.
	2.	Roleplaying the conversation.
	3.	Getting objective feedback after.

This gives you a safe space to fail, iterate, and get better before the real conversation.

â¸»

9. Feedback Hack: Brutal Russian Judge Mode

Instead of â€œGreat job!â€, ask:

â€œBe a Cold War-era Russian Olympic judge. Be brutal. Deduct points for any flinch.â€

AI is otherwise too agreeable. This trick gets you honest, useful critique.

â¸»

10. AI Reflects Your Bias

LLMs demonstrate 100% of human cognitive biases. If you use them passively, theyâ€™ll reinforce bad thinking.

BUT if youâ€™re intentional, you can use them to become a sharper critical thinker.

Custom instruction tip:

â€œI want to preserve sharp critical thinking. Please push back when my logic is weak.â€

â¸»

ğŸ§© Key Philosophical Takeaways
	â€¢	AI â‰  software â†’ AI = collaborator
Treat it like a teammate. Itâ€™s not plug-and-play; itâ€™s relationship-based.
	â€¢	Ideas arenâ€™t the problem â€” execution is.
AI unlocks new adjacent possibilities only if human imagination does too.
	â€¢	AI helps people become more of what they already are
Lazy people become lazier. Critical thinkers become sharper.

â¸»

âœï¸ Actionable Prompts (from talk)
	1.	Chain of Thought Add-On
â€œBefore responding, walk me through your thought process step by step.â€
	2.	Reverse Prompting
â€œBefore starting, ask me for any info you need to do a great job.â€
	3.	Persona Role Assignment
â€œYou are [insert expert/character]. Evaluate this from their perspective.â€
	4.	Few-Shot Prompting
â€œHereâ€™s a good example. Hereâ€™s a bad one. Emulate the good, avoid the bad.â€
	5.	Feedback Mode
â€œAct like a Russian Olympic judge. Brutal, detailed scoring. I can take it.â€
	6.	Tough Conversation Simulation
Use multiple windows: (1) profiler, (2) roleplay, (3) feedback engine.

â¸»

ğŸ§  Best Quote

â€œThe best AI users are not coders. Theyâ€™re coaches.â€

â¸»

âœ… What To Do With This
	â€¢	Start embedding step-by-step reasoning in all your important prompts.
	â€¢	Create example banks for anything repetitive you ask AI to do.
	â€¢	Assign roles and ask AI to â€œpush backâ€ when it disagrees or spots bias.
	â€¢	Use it as a simulation environment for hard convos and feedback loops.
	â€¢	Donâ€™t settle for first outputsâ€”iterate like youâ€™re managing an eager intern.

â¸»
